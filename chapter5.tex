\chapter[Studie und Auswertung]{Studie zur Erhebung multimodaler Interaktionszeiten und Auswertung}\label{cha:Studie}
In diesem Kapitel wird das Studiendesign und die Durchführung der Studie beschrieben, sowie auf die anschließende Auswertung eingegangen. 
\section[Studiendesign]{Studiendesign zur Erhebung multimodaler Interaktionszeiten}
Für die Studie verwenden wir ein Within Subject Design, bei dem jeder Proband alle Kombinationen der vier Anwendungsbeispiele im stehenden Auto durchführen soll.
\subsection[Permutation]{Permutation der Anwendungsbeispiele}
Mit einem festgelegten Moduswechsel und drei verschiedenen Modalitäten (Touch, Gestik und Sprache) kommen wir auf neun Kombinationen pro Anwendungsbeispiel. 
Eine Ausnahme ist das Navigationsanwendungsbeispiel, bei dem wir uns entschieden haben die Zieleingabe nicht für die Gestik umzusetzen. 
Somit fallen die Varianten Geste \& Geste, Sprache \& Geste und Touch \& Geste weg. 
Damit kommen wir bei diesem Anwendungsbeispiel lediglich auf sechs multimodale Kombinationen. 
Zu den multimodalen Varianten testen wir auch die drei unimodalen Varianten der vier Anwendungsbeispiele und kommen insgesamt auf 33 Varianten für alle vier Anwendungsbeispiele, die jeder Proband durchzuführen hat. 
\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{img/Permutation.jpg}
  \caption[Permutation der Anwendungsbeispiel]{Permutation der Anwendungsbeispiel, der unimodalen Varianten und der multimodalen Varianten pro 12 Probanden}
  \label{fig:Permutation}
\end{figure} 

Um Lerneffekte zu vermeiden wurden die vier Anwendungsbeispiele mit dem Balanced Latin Square permutiert. 
Die drei unimodalen Kombinationen wurden mit dem Latin Square permutiert und die sechs multimodalen Kombinationen erneut mit dem Balanced Latin Square. 
Jede Permutation der Modalitäten wurde pro Proband für jedes Anwendungsbeispiel gleich angewendet. 

Beim Anwendungsbeispiel Navigation fielen die Varianten mit Gestik als zweite Modalität weg. 
Bei 12 Probanden ist es möglich die vier verschiedenen Permutationen der Anwendungsbeispiele drei mal zu wiederholen. 
Die drei unimodalen Kombinationen werden vier mal wiederholt und die sechs Permutationen der multimodalen Kombinationen werden zwei mal innerhalb von 12 Probanden wiederholt. 
Zudem wird die Reihenfolge von unimodalen und multimodalen abgewechselt siehe \fref{fig:Permutation}. Dieses Vorgehen wird für die nächsten 12 Probanden wiederholt. 
Die drei verschiedenen Zieleingaben werden ebenfalls mit dem Latin Square permutiert und auf die permutierte Moduskombination verteilt. 
Mit diesen Vorkehrungen können wir davon ausgehen, dass mögliche Lerneffekte gleich verteilt sind.   
\subsection[Fragebögen]{Fragebögen der Studie}
Es wurden zwei verschiedene Fragebögen erstellt (siehe Anhang im Kapitel \ref{cha:Anahng}). 
Im ersten Fragebogen werden demografischen Angaben wie Name , Alter, Händigkeit und die Muttersprache abgefragt. 
Außerdem die bereits gesammelten Erfahrungen im Umgang mit Interaktionen durch Touch, Geste und Sprache. 
Hier wurden, auf die Frage der Nutzungshäufigkeit, vier Antwortmöglichkeiten unterschieden:
\begin{itemize}
	\item ja, benutze ich regelmäßig 
	\item ja, benutze ich gelegentlich
	\item ja, aber nur sehr wenig
	\item nein
\end{itemize}

Nach jedem durchgeführten Messdurchgang eines Anwendungsbeispiels wurde innerhalb der Unityanwendung eine Bewertung abgefragt, wie geeignet die Probanden die eben ausgeführte Aufgabe fanden und wie sehr Ihnen die Aufgabe gefallen hat. 
Mit Touch als Eingabemodalität soll eines der fünf Symbole gewählt werden siehe \fref{fig:Smileys}.
\begin{figure}
	\centering
		\includegraphics[width=0.7\textwidth]{img/Smileys.JPG}
	\caption[Eignung und Gefallen eines Anwendungsbeispiels]{Eignung und Gefallen eines Anwendungsbeispiels. Verwendung der Icons siehe Kapitel \ref{cha:Danksagung}.
}
	\label{fig:Smileys}
\end{figure}

Der zweite Fragebogen wird nach der Durchführung der Studie ausgefüllt. 
Darin wird abgefragt, wie geeignet die Modalitäten für die verschiedenen Screentypen sind. 
Dies wird mit einer Likertskala mit 5 Auswahlmöglichkeiten für jede Modalität abgefragt.  
Die Auswahlmöglichkeiten gehen von nicht geeignet bis geeignet. 
Außerdem wird ein Ranking für die verschiedenen Screentypen abgefragt, indem sich der Proband entscheiden muss welcher Modus für die unterschiedlichen Screentypen am besten, zweitbesten und am schlechtesten geeignet ist.  

Die kompletten Fragebögen, Einverständniserklärung, sowie der Studienleitfaden sind am Ende dieser Arbeit angehängt, siehe Kapitel \ref{cha:Anhang}.
\section{Durchführung der Studie}
Die Studie fand in Garching-Hochbrück in der Parkgarage von BMW in einem 6er Gran Coupé statt (siehe \fref{fig:GranCoupe}). 
Die Studiendauer betrug circa 1,5 Stunden. 
Das Auto wurde am Strom angeschlossen, um das Surface zu laden und eine Dauerhafte Stromversorgung für Licht sowie Sitzheizung zu ermöglichen.
\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{img/GranCoupe.jpg}
  \caption{BMW 6er Gran Coupé in der Parkgarage}
  \label{fig:GranCoupe}
\end{figure} 
Das Surface wurde vor das ursprüngliche Display am Dashboard angebracht. 
Der Interaktionsbereich befand sich somit auf gleicher Höhe (siehe \fref{fig:AnbringungSurface}), jedoch etwas weiter vorne, was für den Touch auch geeigneter ist. Die Auflösung des Surface musste auf 1240x800 Pixel reduziert werden, damit die Darstellung groß genug war. Die Buttons auf dem ersten und zweiten Screen hatten somit eine Größe von 3,5 mal 4,5 cm. 

Die Leap Motion, zur Erkennung der Gesten, wurde zwischen Gangschaltung und Dashboard angebracht. 
Somit konnte die Hand bereits am Lenkrad erkannt werden, befand sich allerdings noch nicht im Interaktionsbereich, um Gesten auszuführen. 
\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{img/AutoSetting2.jpg}
  \caption{Anbringung des Surface im Auto}
  \label{fig:AnbringungSurface}
\end{figure} 
Pro Tag konnten bis zu vier Probanden an der Studie teilnehmen. 
Bevor der erste Durchgang begann wurde das Auto am Strom über den Kofferraum angeschlossen. 
Der Akku der Go Pro wurde ausgetauscht und eine leere Speicherkarte eingelegt. 
Im Kofferraum konnten Ersatzbatterien für die Kamera geladen werden. 
Nach jedem Probanden wurde der Akku gewechselt und der gebrauchte erneut geladen. 
Die Speicherkarten von 32GB wurden immer nach zwei Probanden gewechselt und anschließend auf eine Festplatte kopiert. 
Die Kamera wurde mittig, zwischen Fahrer und Beifahrer an der Decke befestigt und Richtung Surface ausgerichtet siehe \fref{fig:Kamera}.
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.5\textwidth]{img/Kamera3.jpg}
  \caption{Anbringung der Kamera im Studienauto}
  \label{fig:Kamera}
\end{figure} 

Das Surface wurde wie oben beschrieben angebracht und die Leap, sowie die externe Tastatur über einen Hub angeschlossen. Der Verteiler war ebenfalls an den Strom angeschlossen und wurde auf der Beifahrerseite zwischen Gurt und Mittelkonsole eingeklemmt siehe \fref{fig:Hub}. 
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.5\textwidth]{img/Hub.jpg}
  \caption{Anschluss für die Leap Motion und der externen Tastatur}
  \label{fig:Hub}
\end{figure} 

Jeder Proband wurde am Empfang bei BMW am Parkrings 19 abgeholt und begrüßt.
Es wurde darauf hingewiesen, dass die Studie bis zu 1,5 Stunden dauern wird und das jetzt die beste Gelegenheit wäre, um wenn nötig noch auf die Toilette zu gehen.
Anschließend begaben wir uns in die Parkgarage zum Testfahrzeug, indem der Proband auf dem Fahrersitz platz nehmen sollte, während der Studienleiter am Beifahrersitz platz nahm.
Der Proband wurde darauf hingewiesen seinen Sitz einzustellen, als würde er oder sie das Auto fahren.

Nachdem sichergestellt wurde, dass alle Smartphones auf lautlos gestellt sind, wurde das Thema kurz erläutert und darauf aufmerksam gemacht, dass zur Erhebung der Interaktionszeiten verschiedene Daten protokolliert werden und zusätzlich die Studie mit einer Go Pro aufgezeichnet wird.

Darüber aufgeklärt musste jeder Proband eine Einverständniserklärung unterschreiben \ref{cha:Anhang}.
Zusätzlich sollte ein kurzer Fragebogen zu demografischen Daten und den Vorerfahrungen zum Umgang mit den Interaktionen Touch, Geste und Sprache ausgefüllt werden.

In der Zwischenzeit startete der Studienleiter das Programm, stellte die richtige ID ein und überprüfte die neu geladene Permutation.
Jetzt wurde das Vorgehen der Studie anhand des ersten Anwendungsbeispiel mit Hilfe der ausgedruckten Übersicht der Anwendungsbeispiele \ref{fig:UseCases} erläutert.

Sobald das erste Anwendungsbeispiel und die Vorgehensweise klar war, wurde die Go Pro gestartet und der Proband konnte mit dem ersten Probedurchlauf beginnen. Dazu hatte der Proband seine Hände am Lenkrad und der Studienleiter startete die Anwendung mit seiner externen Tastatur. 
Der Screen wird nach dem Start zuerst für 3 Sekunden schwarz bis dann der Hauptscreen zu sehen ist und die Interaktion beginnen kann.
Insgesamt gibt es 33 verschiedene Durchläufe, die jeder Proband testen soll.
Zu jedem dieser Varianten, bestehend aus den 4 Anwendungsbeispielen und deren Moduskombinationen, sollte mindestens ein Probedurchlauf gemacht werden.

Der Probedurchlauf dient dazu den Probanden mit der Aufgabe vertraut zu machen und sich an die möglicherweise neue Interaktionsmethode zu gewöhnen.
Die Probedurchläufe wurden so oft wiederholt, bis der Studienleiter das Gefühl hatte, dass die Aufgabe klar verstanden wurde. 

Nach dem Probedurchlauf werden zwei Messdurchgänge durchlaufen, die für die Erhebung der Interaktionszeiten verwendet wird.
Da wir nur fehlerfreie Messdurchgänge benötigen, wurde im Falle eines Fehlers in einem Messdurchgang, dieser wiederholt.
Passierte dies kennzeichnete der Studienleiter dies in seinen Notizen zu dieser Variante, um später nur die gültigen Messdurchgänge zu verwenden.
Auch interessante Anmerkungen oder Auffälligkeiten wurden während der Studie notiert.

Nach den mindestens 99 Durchgängen $((1 * \text{Probedurchgang} + 2 * \text{Messdurchgänge}) * 33 \text{Varianten})$ konnte die Kamera gestoppt werden und die Probanden sollten den anschließenden Fragebogen ausfüllen.
Währenddessen konnten Anmerkungen vom Versuchsleiter notiert werden. 
Als Dankeschön bekamen die Probanden nach der Studie Schokolade.

Nach jedem Studiendurchgang wurde der Akku der Kamera gewechselt. Die Speicherkarte wurde nach jedem zweiten Probanden gewechselt.
\section[Quantitative Auswertung]{Quantitative Auswertung der Studienergebnisse}
Im folgenden werden die quantitativen Ergebnisse der Studie präsentiert.
In einem Zeitraum von 2 Wochen nahmen insgesamt 22 Probanden an der Studie zur Erhebung der Interaktionszeiten teil.
hierbei wurden über 22 Stunden Videomaterial aufgezeichnet. 
\subsection[Studienteilnehmer]{Studienteilnehmer}
Das Alter der 22 Studienteilnehmer (14 männlich und 8 weiblich) beträgt im Durchschnitt 30,55 Jahre. 
Der Altersbereich erstreckt sich von 22 bis 58 Jahren. 
Mode und Median ergaben je 25 Jahre. 19 der 22 Probanden sind rechtshändig, 2 linkshändig und ein Proband gab an beidhändig zu sein. 
Alle Teilnehmer sprechen deutsch als Muttersprache.

Die Vorerfahrungen mit der Bedienung von Touch, Gesten und Sprache der Teilnehmer wurde von den Probanden abgefragt und von den Probanden eingeschätzt. 
Auf die Frage, ob sie Erfahrung mit der Bedienung von Sprache, Touch und Geste haben, konnte aus vier Optionen gewählt werden (1: nein, 2: ja, aber nur sehr wenig, 3: ja, benutze ich gelegentlich und 4: ja, benutze ich regelmäßig). 

Die Vorerfahrung von Sprache ergab im Durchschnitt 2,32, bei Touch 3,95 und bei Geste 1,86. Die genauen Angaben der Probanden können aus \fref{fig:Vorerfahrung} entnommen werden.
\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{img/ErfahrungProbanden2.jpg}
  \caption[Vorerfahrung der Probanden]{Vorerfahrung der Probanden mit der Bedienung von Touch, Sprache und Geste. Einschätzung der Probanden auf die Frage: Haben Sie Erfahrung bei der Bedienung von Sprach-, Touch- und Gestensteuerung.}
  \label{fig:Vorerfahrung}
\end{figure} 
\subsection[User Experience]{User Experience}
Nach jedem Messdurchgang wurden die Nutzer gefragt wie geeignet Sie diese Interaktion fanden und, ob sie Ihnen gefallen hat. Es gibt 5 Antwortoptionen. Zwei negative, eine neutrale und zwei positive. Aus den Antworten ist deutlich zu sehen, dass die unimodale Variante mit Sprache in beiden Bereichen immer am besten abschnitt. Die Unterschiede zwischen Eignung und Gefallen sind nicht sehr groß, allerdings fällt auf, dass vor allem die Interaktionen mit Geste den Nutzern besser gefällt als sie deren Eignung einschätzen. Am zweit beliebtesten in beiden Kategorien war die Kombination von Touch und Sprache. Bei dem Anwendungsbeispiel Lautstärke war die Kombination Touch und Sprache sogar in Eignung und Gefallen noch etwas besser als die unimodale Sprachvariante. Die dritt beliebteste Variante vom Lautstärkebeispiel war die Kombination Sprache und Touch. Bei allen anderen Anwendungsbeispielen war die dritt beliebteste Kombination Geste und Sprache. 

Grundsätzlich lässt sich sagen, dass die Mehrheit der Probanden die Sprache am geeignetsten empfanden. Nur für die Direktauswahl aus sichtbaren Elementen schnitt Touch etwas besser ab als Sprache. Die Geste hat bei der Direktauswahl die besten Ergebnisse verglichen zu den anderen Operatoren. Ein sehr eindeutiges Ergebnis aus den Fragebögen bekommen wir bei der Texteingabe, die eindeutig für Sprache besser geeignet ist, als per Touch das gewünschte Ziel einzutippen siehe \fref{fig:Uebersicht_Eignung}.
\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{img/Uebersicht_Eignung}
  \caption[Eignung des Screentypen]{Einschätzung der Probanden, wie geeignet Sie die verschiedenen Screentypen für die jeweilige Modalität halten. Die Balkendiagramme zur Darstellung von Likert-Skalen wurde mit http://likertplot.com/ generiert.}
  \label{fig:Uebersicht_Eignung}
\end{figure}

Im zweiten Teil des Fragebogen sollten die Screentypen noch mit einem Ranking bewertet werden. Hier mussten sich die Probanden entscheiden welcher Modus am besten zweitbesten und am schlechtesten geeignet ist. Bei der Direktauswahl aus sichtbaren Elementen halten 10 von 22 die Toucheingabe am geeignetsten. 8 die Sprachbedienung und 4 die Gestensteuerung. Bei den restlichen Screentypen wird die Sprachbedienung am häufigsten für am geeignetsten gehalten. Sehr eindeutig sind sich die Probanden bei der Texteingabe einig. 21 von 22 finden die Spracheingabe dort geeigneter als das Ziel Buchstabe für Buchstabe einzutippen.

\subsection[Ermittlung der Zeiten der Aktionen]{Ermittlung aller Zeiten der Aktionen}
Um die Zeiten der Operatoren zu ermitteln werden die Differenzen zwischen den gewünschten protokollierten Events berechnet. Dafür musste zuerst unsere Protokollierung etwas aufbereitet werden. Als erstes wurde die Logdatei in eine Excelltabelle in Tabellenformat geladen. Somit können für die Auswertung nach beliebigen Kriterien die Spalten gefiltert und sortiert werden. 

Fehlerhafte Messdurchgänge wurden anhand der Notizen während der Studie als fehlerhaft markiert. In einigen wenigen Fällen gab es bei manchen Kombinationen drei statt zwei Messdurchgängen. Hier wurde der dritte Durchgang immer behalten und von den ersten beiden der schlechteste verworfen. Bei Unklarheiten konnte das Videomaterial zur Überprüfung hinzugezogen werden, bis es zu jedem Probanden zwei fehlerfreie Messdurchgänge in jeder Kombination gab. 

Für die Berechnungen der verschiedenen Zeiten wurden die protokollierten Events verwendet. Ein Beispiel dafür wäre die Zeit, die ein Nutzer benötigt, bis der erste Button gedrückt wird (DA des ersten Screens). Als Startzeit wurde die protokollierte Zeit vom Event "`MainUI"' benutzt. Der Screen des Hauptmenüs heißt MainUI. Da unsere Interaktion begann, sobald der Hauptscreen zu sehen war entspricht das laden dieser Szene unserem Startpunkt. Dafür wurde eine neue Spalte der Excelltabelle angelegt mit dem Titel StartScreen1 und immer wenn das protokollierte Event "`MainUI"' in der Spalte "`Szenen"' gefunden wird, wird diese Zeit aus der Spalte "`ms Gesamt"' in die neue Spalte geschrieben. Wenn die Bedingung nicht erfüllt ist, wird der Wert der Zelle darüber in die Zelle geschrieben. Gibt man folgende Formel in die Spalte ein wird sie automatisch in der kompletten Spalte berechnet.  
\begin{lstlisting}
=IF([@Szenen]="MainUI";[@[ms Gesamt]];AJ59)
\end{lstlisting}
Das Ende der Aktion ist das Event "`Button geklickt: (Name der 4 Buttons)"'. Dafür wurden alle vier Buttons (Telefon, Navigation, Medien und Temperatur) des Hauptscreens verwendet. 
Um daraus jetzt eine Dauer für eine Aktion zu berechnen wurde die Differenz der Zeitpunkte berechnet und durch 1000 geteilt um die Zeit in Sekunden zu bekommen.
\begin{lstlisting}
=IF([@[Endzeit Spalte]]-[@[Startzeit Spalte]]>0;
([@[Endzeit Spalte]]-[@[Startzeit Spalte]])/1000;0)
\end{lstlisting}

Mit Berechnungen dieser Art wurden alle Zeiten ermittelt. Die Tabelle kann nach Anwendungsbeispiel, Moduskombination und Event sortiert werden, um die gewünschten Zeiten für die Auswertung zu verwendet. Anzumerken ist, dass diese Art der Berechnung auch Antwortzeiten des Systems beinhalten. Wir werden uns relevante Größen separat anschauen, um diese später als konstanten Wert im Modell zu berücksichtigen. Zum Beispiel haben wir eine Animation einer scrollenden Liste eingebaut, um dem Nutzer ein besseres Feedback zu gewährleisten. Diese Animationszeit wird separat als Antwortzeit unseres Prototypen betrachtet. 

Im folgenden schauen wir uns die Ergebnisse der Studie an. Wir gehen in diesem Abschnitt noch nicht auf Signifikante Unterschiede ein, sondern schauen uns erst mal die Ergebnisse und deren Auffälligkeiten an. 

Die ersten beiden Screens für die Anwendungsbeispiele Telefon, Navigation und Medien und der erste Screen für das Anwendungsbeispiel Temperatur, bestehen je aus einer Direktauswahl aus sichtbaren Elementen (DA). Der Startpunkt der Berechnung war das laden des Hauptmenüs. Die Nutzer wurden angewiesen mit der Interaktion zu beginnen, sobald sie den Hauptscreen sehen. Das Ende der Direktauswahl aus sichtbaren Elementen war das protokollierte Event das der Button geklickt wurde. Je nach Anwendungsbeispiel (Telefon, Navigation, Medien und Temperatur) musste ein anderer Button selektiert werden. Es wurden alle 4 verschiedene Button einmal verwendet, siehe \fref{fig:UseCases}.
\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{img/DA_Screen12.JPG}
  \caption[Durchschnittszeiten in Sekunden der Direktauswahl]{Durchschnittszeiten und Medianwerten in Sekunden der Direktauswahl beider Screens für alle Moduskombinationen. T steht für Touch, S für Sprache und G für Geste.}
  \label{fig:DA_Screen12}
\end{figure}
In \fref{fig:DA_Screen12} werden die Durchschnittszeiten von allen Moduskombinationen der beiden Screens abgebildet. Für diese Aktion spielt jedoch nur der erste Modus eine Rolle, da der Moduswechsel erst anschließend statt findet. Die Auswahl der Buttons per Touch ist auf beiden Screens am schnellsten. Im ersten Screen liegen die Interaktionszeiten für Geste und Sprache sehr nah zusammen. Im zweiten Screen dauert die Spracheingabe deutlich länger als mit Geste.
Wie zu erwarten scheint der nachfolgende Modus keinen großen Einfluss auf die Interaktionszeit zu nehmen. Uns interessiert im speziellen der Einfluss nach einem Wechsel. 

Die nächsten Aktionen finden nach einem potentiellen Moduswechsel statt. Die Modalität, die in dieser Aktion ausgeführt wird ist somit die zweite Modalität. Im Falle der unimodalen Variante findet kein Moduswechsel statt. Findet ein Moduswechsel statt bezeichnen wir im folgenden die zusätzliche Zeit als Wechselkosten. Sie beinhalten einen mentalen Operator und den Homing Operator, da bei einem Moduswechsel zu Geste oder Touch die Position der Hand geändert wird.

Die erste Aktion, die wir uns nach einem Moduswechsel ansehen, ist die Aktion Listennavigation (L). Die Probanden mussten im Anwendungsbeispiel Telefon die Liste um 3 Seiten inkrementieren und schließlich den Kontakt "`Maria Müller"' durch eine Direktauswahl wählen. Im ersten Swipe stecken unsere Wechselkosten mit drinnen, weswegen dieser auch deutlich länger dauert, als die anderen beiden Swipes siehe \fref{fig:Swipe13Phone}. Der Startpunkt des ersten Swipes ist der Zeitpunkt, sobald der Screen mit der Liste geladen wurde. Wurde die Liste um eine Seite gescrollt, ist das der Endpunkt des ersten Swipes und gleichzeitig der Startpunkt des zweiten Swipes und genauso für den Dritten. 
\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{img/Swipe1-3_Phone.JPG}
  \caption{Durchschnittszeiten für Swipe 1, 2 und 3 in Sekunden der Liste für die Moduskombinationen von Touch und Geste}
  \label{fig:Swipe13Phone}
\end{figure}
Es fällt auf, dass beim ersten Swipe die unimodalen Varianten schneller sind als die multimodalen Varianten. Der Wechsel einer Modalität benötigt etwas mehr Zeit, da der mentale Operator wahrscheinlich etwas länger dauert und auch die Umpositionierung der Hand wegfallen kann. 

Anschließend folgt die Aktion Direktauswahl innerhalb der Liste von "`Maria Müller"', siehe \fref{fig:DA_Swipe}. Es ist eine deutlich kürzere Zeit als die Direktauswahl vom ersten Screen, da sich die Hand des Nutzer bereits im richtigen Interaktionsbereich befindet. Daher sollten wir diese Aktion zusätzlich unterscheiden. Die Direktauswahl aus sichtbaren Elementen innerhalb der Liste startet unmittelbar nach dem dritten Swipe und endet mit der Selektion des Button "`Maria Müller"'.
\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{img/DA_Swipe.JPG}
  \caption{Durchschnittszeiten in Sekunden für die Direktauswahl innerhalb der Listen Aktion}
  \label{fig:DA_Swipe}
\end{figure}

Die Touchzeiten der Texteingabe durch Buchstaben, der drei verschiedenen Ziele können aus \fref{fig:TouchzeitenB_Ges} entnommen werden. Es ist deutlich ein Muster zu erkennen. Der erste Buchstabe dauert am längsten, da hier erneut die Wechselkosten hinzukommen. Auch bei dieser Aktion des ersten Buchstaben ist die unimodale Variante mit 1,765 Sekunden (Touch-Touch) im Durchschnitt schneller als die Multimodalen Varianten mit 1,990 Sekunden (Geste-Touch) und 1,983 Sekunden (Sprache-Touch) . Der zweite und dritte Buchstabe ist schon deutlich schneller und alle weiteren Buchstaben nähern sich dem Wert einer halben Sekunde an. Der Start der Texteingabe beginnt wieder mit dem laden der Szene des Texteingabescreen. Jeder Buttonklick eines Buchstaben ist die Endzeit des vorherigen Buchstaben und die Startzeit des nächsten Buchstabens.
\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{img/TouchzeitenBuchstabenGesamt.jpg}
  \caption{Durchschnittszeiten für Touch in Sekunden der einzelenen Buchstaben}
  \label{fig:TouchzeitenB_Ges}
\end{figure}
\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{img/TouchzeitenKategorien.JPG}
  \caption[Kategorien der Buchstaben für Wörter.]{Kategorien der Buchstaben für Wörter. Hier wurden von den drei verschienenen Zielen (Rom, Dirfweg und Kirchngasse) jeweils die ersten, zweiten und dritten und alle weiteren Buchstaben zusammengefasst.}
  \label{fig:Kategorien}
\end{figure} 

In \ref{fig:TouchzeitenB_Ges} kann man deutlich erkennen, dass sich der zweite und dritte Buchstaben nicht deutlich unterscheiden und die restlichen Buchstaben nochmals schneller eingegeben wurden. Wir haben Deshalb entschlossen beim ersten Buchstaben den vorherigen Modus zu unterscheiden. Den zweiten und dritten Buchstaben zusammenzufassen und für alle weiteren Buchstaben den Durchschnitt dieser zu verwenden. Wir haben also 3 Kategorien. Der erste Buchstabe mit Unterscheidung der vorherigen Modalität, eine gemeinsame Zeit für den zweiten und dritten Buchstaben und als letztes eine Zeit für alle weiteren Buchstaben \ref{fig:Kategorien}.

Bei der Sprache ist das Ergebnis weniger deutlich (siehe \ref{fig:SpracheZiel}). Was allerdings klar zu erkennen ist, dass Rom immer am schnellsten war. Bei Dorfweg und Kirchengasse ist es nicht so eindeutig. Auch hier ist das Laden der Szene der Startpunkt und das Ende ist das Event, indem das Inputfeld mit dem Ziel gefüllt wird.
\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{img/SpracheZiel.JPG}
  \caption{Durchschnittszeiten in Sekunden der Ziele für Sprache}
  \label{fig:SpracheZiel}
\end{figure} 

Nach dem Touch und den Spracheingaben der Ziele wird noch die Bestätigung des OK Buttons gemessen. Die Aktion startet mit dem letzten Buchstaben der Toucheingabe oder dem Aktualisieren des Inputfeld der Spracheingabe. Der Moduswechsel fand bereits statt und wie auch zu erwarten sind die Abweichungen zum vorherigen Modus sowohl bei Touch, als auch bei der Spracheingabe sehr gering (siehe \ref{fig:Bestaetigung_OK}).
\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{img/B_OK.jpg}
  \caption{Durchschnittszeiten und Medianwerte in Sekunden für die Bestätigung der Texteingabe.}
  \label{fig:Bestaetigung_OK}
\end{figure} 

Im Anwendungsbeispiel Medien folgt im dritten Screen die Aktion direkte Inkrementation (Inkr. (d)) durch den Slider (siehe \fref{fig:Slider}) mit einem anschließendem Popup (siehe \fref{fig:Popup}). Auch hier ist das Laden der Szene der Startpunkt der Aktion. Sobald der Slider im gewünschten Bereich von 75-85\% losgelassen wird endet die Aktion und das Popup wird sichtbar. Das Ende der Aktion Inkr. (d) ist der Start der Bestätigungsaktion B. Diese endet mit dem Button Klick des Popups.
\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{img/Slider.JPG}
  \caption[Durchschnittszeiten für Inkr. (d)]{Durchschnittszeiten in Sekunden für die Aktion Slider von 50 auf 75 bis 85 Prozent für alle Moduskombinationen}
  \label{fig:Slider}
\end{figure} 
\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{img/PopupBestaetigung.JPG}
  \caption[Durchschnittszeiten für die Bestätigung des Popups]{Durchschnittszeiten in Sekunden für die Bestätigung des Popups für alle Moduskombinationen}
  \label{fig:Popup}
\end{figure} 
Auch bei den Zeiten für (Inkr. (d)) bestätigt sich erneut, dass die unimodalen Varianten schneller sind als die multimodalen Varianten. Bei dem anschließenden Popup hat der Moduswechsel bereits stattgefunden und es ist auch zu erkennen, dass sich die Zeiten hier zum vorherigen Modus nicht mehr so stark unterscheiden.

Als letzte Aktion bleibt noch die stufenweise Inkrementation Inkr. (s) im Anwendungsbeispiel Temperatur (siehe \fref{fig:SwipeKlima}). Der Startpunkt beginnt mit dem Laden der Szene für die Einstellung der Temperatur. Der erste Swipe endet genau wie bei der Listennavigation L mit dem Erreichen der nächsten Seite. Hier startet gleichzeitig der nächste Swipe bis wir bei der gewünschten Seite mit dem dritten Swipe angekommen sind. Es folgt eine Verzögerung bis der Wert eingeloogt wird. Diese wird in die Gesamtzeit nicht miteinbezogen, da das Ziel bereits erreicht ist. 

Auch hier ist deutlich zu sehen, dass der erste Swipe am längsten dauert und sich Swipe 2 und 3 hingegen sehr ähnlich sind. Die unimodalen Varianten beim ersten Swipe sind ebenfalls schneller als bei den multimodalen Varianten.
\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{img/Swipe1-3_Klima.JPG}
  \caption[Durchschnittszeiten für Inkr. (s)]{Durchschnittszeiten für Swipe 1, 2 und 3 in Sekunden der Wertinkrementation für die Moduskombinationen von Touch und Geste}
  \label{fig:SwipeKlima}
\end{figure} 

Wir haben jetzt unsere Aktionen ausgewertet und einen Blick auf die verschiedenen Zeiten geworfen, im folgenden werden die Zeiten auf Ihre statistische Signifikanz untersucht. 

\subsection[Statistische Tests]{Statistische Tests der Aktionszeiten}
Mit einer One-Way Repeated Measures ANOVA wurde mit Hilfe von SPSS für jede Aktion geprüft, ob der zweite Modus einen signifikanten Einfluss auf den ersten Modus hat und vor allem ob der erste Modus einen signifikanten Einfluss auf den zweiten Modus hat. Die anhängige Variable war dabei der Modus (Touch, Geste und Sprache) und es wurden die wiederholten Messungen der Zeiten verglichen. 

Bei diesem Test muss beachtet werden, dass die Sphärizität nicht verletzt wird. \citet{field2002design} erklärt in seinem Buch "`How to Design and Report Experiments"' wie dies in SPSS berücksichtigt wird. Ist bei Mauchly's Test der Sphärizität das Ergebnis signifikant wird die Sphärizität verletzt und es muss eine Korrektur vorgenommen werden. Wir verwenden bei unseren Ergebnissen hier die Greenhouse-Geisser Korrektur. Ist bei Mauchly's Test der Sphärizität das Ergbenis nicht signifikant ist die Sphärizität auch nicht verletzt und es kann beim Test der Inner-Subjekt Effekten der Wert aus der Zeile entnommen werden, indem die Sphärizität angenommen wird \citep{field2002design}.

\section[Herleitung des Modells]{Ableitung des multimodalen Modells aus den gewonnen Interaktionszeiten}
Aus unserer Studie haben wir Zeiten für verschiedene Aktionen in den jeweiligen Moduskombinationen erhoben. Die Zeiten in den folgenden Tabellen sind die Durchschnittszeiten für eine Aktion, der in einer bestimmten Moduskombination ausgeführt wurde. Wird eine Aktion in der Modalität Touch (T) ausgeführt gibt es 3 mögliche Modalitäten, die nach einem Wechsel kommen können. Entweder ebenfalls Touch und somit Touch\&Touch (TT) oder es folgt Geste und ergibt Touch\&Geste (TG) oder Touch\&Sprache (TS), wenn Sprache nach dem Touch folgt. Die gleichen Kombinationen gibt es auch wenn Geste oder Sprache der erste Modus ist. 

Aus unseren Anwendungsbeispielen haben sich verschiedene Einzelaktionen ergeben, die wir jetzt analysieren wollen, um daraus unser Modell zu modellieren.
In der folgenden Liste werden die einzelnen Aktionen der Anwendungsbeispiele erläutert (siehe auch Anwendungsbeispiele in \fref{fig:UseCases}):
\begin{itemize}
	\item \textbf{DA$_1$, DA$_2$:} Direktauswahl aus sichtbaren Elementen des ersten/zweiten Screen. Dieser beinhaltet beim ersten Screen 4 Buttons, die durch Symbole und Titel gekennzeichnet sind und beim zweiten 3 Buttons, die durch Text auf den Buttons gekennzeichnet sind.
	\item \textbf{L$_1$, L$_2$ und L$_3$:} Der erste (zweite oder dritte) Swipe der Liste aus dem Anwendungsbeispiel Telefon. 
	\item \textbf{DA (L):} Direktauswahl aus sichtbaren Elementen, nachdem im Anwendungsbeispiel Telefon bereits drei mal geswiped wurde und nur noch Maria Müller aus vier Elementen ausgewählt werden muss.	
	\item \textbf{Maria M.:} Zeit, die benötigt wird mit dem Sprachbefehl den Kontakt auszuwählen (Animationszeit ist abgezogen)
	\item \textbf{Inkr. (s)$_1$, Inkr. (s)$_2$ und Inkr. (s)$_3$:} Der erste (zweite oder dritte) Swipe der Wertinkrementation aus dem Anwendungsbeispiel Temperatur. 
	\item \textbf{Inkr. (d)} Verschiebung des Sliders im Anwendungsbeispiel Medien. Beim Modus Sprache entspricht das dem Sprachbefehl "`achzig Prozent"'.
	\item \textbf{Popup:} Bestätigung des Popup, das nach dem Slider angezeigt wird.
	\item \textbf{1. Bu., 2. Bu., 3. Bu.:} Der Touch des ersten (zweiten oder dritten) Buchstaben im Anwendungsbeispiel Navigation. 
	\item \textbf{Bu. >3:} Alle weiteren Buchstaben im Anwendungsbeispiel Navigation.
	\item \textbf{Wort S, M, L:} Kurzes Wort (Rom), mittellanges Wort (Dorfweg) und langes Wort (Kirchengasse).
	\item \textbf{OK:} Bestätigung der Zieleingabe im Anwendungsbeispiel Navigation. 
	\item \textbf{R(Screen):} Konstante Zeit, die vom System benötigt wird von einem Screen auf den nächsten zu wechseln. Ein Wechsel dauert 0,016 Sekunden pro Screenwechsel.
	\item \textbf{R(Swipe):} Beim Modus Sprache wird nach dem Sprachbefehl: "`Maria Müller"' die Liste mit einer Animation zur richtigen Seite geswiped bevor der gewünschte Kontakt ausgewählt wird. Die Zeit dieser Animation nennen wir R(Swipe) und dauert mit unserem Prototypen 1,5 Sekunden.
	\item \textbf{R(DA):} Beim Modus Sprache wurde bei der DA nach jedem Sprachbefehl 0,5 Sekunden gewartet um die gelbe Markierung als Feedback zu sehen. Diese 0,5 Sekunden müssen also bei DA$_1$ und DA$_2$ für die Gesamtzeit hinzugefügt werden.
\end{itemize}
Diese Einzelaktionen wollen wir in diesem Kapitel im Hinblick der Modalitätsunterschiede untersuchen und diese so weit es sinnvoll ist aggregieren, um ein übertragbares Modell zu bekommen.

Für die Sprachmodalität haben wir nicht alle Aktionen abgebildet. Statt zum Beispiel in einer Liste aus Kontakten durch einen Sprachbefehl "`nächste Seite"' zu scrollen , erschien es uns sinnvoller hier direkt den Kontakt "`Maria Müller"' auszuwählen. Ebenso beim Einstellen der Temperatur oder der Lautstärke wurde der gewünschte Wert direkt, ohne Inkrementation, gesagt. Wir werden dafür die Zeiten von verschiedenen Wortlängen untersuchen. 

Für uns am interessantesten in diesem Modell ist, ob ein vorheriger Modus Einfluss auf den nachfolgenden Modus hat und ob und wie sich die Interaktionszeiten dadurch unterscheiden. Die Zeiten wurden als Durchschnitt der Zeiten der 22 Probanden ermittelt. Die Durchschnittszeiten aller Aktionen sind in \fref{tab:OperatorzeitenVorWechsel1}, \fref{tab:OperatorzeitenNachWechsel_TouchGeste} und \fref{tab:OperatorzeitenNachWechsel_Sprache} zu sehen. 
\begin{table}[ht]
  \centering
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|}
		\hline
		& \multicolumn{3}{|c|}{Touch (T)} & \multicolumn{3}{|c|}{Geste (G)}&\multicolumn{3}{|c|}{Sprache (S)}\\
		\hline
		Aktion 					& TT 		& TG 		& TS 		& GT 		& GG 		& GS 		& ST 		& SG 		& SS\\
		\hline
		DA$_1$ 	& 1,617 & 1,720	& 1,666 &	2,695	&	\textbf{2,595}	&	\textbf{2,833}	&	2,663	& 2,610	& 2,605\\
					&  			&  			&				&				&		\small{$(GS)^*$}					&	\small{$(GG)^*$}			 			&		&	& \\
		\hline
		DA$_2$ 	& 1,715 & \textbf{1,813}	& \textbf{1,728}	&	2,131	&	2,174	&	2,187	&	2,981	&	2,949	& 2,966\\
					&  			& \small{$(TS)^{**}$}				&	\small{$(TG)^{**}$}			&				&				&				&		&	& \\
		\hline			
  \end{tabular}
	\caption[Durchschnittszeiten der Aktionen vor dem Moduswechsel]{Durchschnittszeiten in Sekunden der Aktionen vor dem Moduswechsel. Signifikanz wurde gemessen innerhalb einer Modalität vor dem Wechsel (zum Beispiel TT, TG und TS). Fettgedruckte Zeiten sind signifikant. Unter der Zahl steht zu welcher Kombination diese Zeit signifikant ist. Dabei gilt zusätzlich: * $\text{Signifikanz} \leq 0,05$, ** $\text{Signifikanz} \leq 0,01$ und *** $\text{Signifikanz} \leq 0,001$}
\label{tab:OperatorzeitenVorWechsel1}
\end{table}

\begin{table}[ht]
  \centering
	\begin{tabular}{|l|l|l|l|l|l|l|}
		\hline
		& 					\multicolumn{3}{|c|}{Touch (T)} & \multicolumn{3}{|c|}{Geste (G)}\\
		\hline
		Aktion 					& TT 	& GT 	& ST 	& TG 	& GG 	& SG 	\\
		\hline
		L$_1$				& $\textbf{1,518}$ 				& $\textbf{1,929}$				& $\textbf{1,893}$ 				&	1,902	&	$\textbf{1,797}$					&	$\textbf{2,190}$		\\
									& \small{$(GT, ST)^{***}$}	&	\small{$(TT)^{***}$}			& \small{$(TT)^{***}$}			&				&	\small{$(SG)^{**}$}				&	\small{$(GG)^{**}$}	\\
		\hline
		L$_2$			& 0,764 & 0,758	& 0,771 &	1,403	&	1,529	&	1,504 \\
		\hline
		L$_3$				& 0,884 & 0,883	& 0,818 &	1,271	&	1,336	&	1,191	\\
		\hline
		DA (L)				& 1,056 & 1,141	& 0,945 &	2,366	&	2,118	&	2,291	\\
		\hline
		Inkr. (s)$_1$				& $\textbf{1,453}$ 				& $\textbf{1,789}$		& $\textbf{1,726}$ 			&	1,672	&	$\textbf{1,536}$			&	$\textbf{1,745}$\\
									& \small{$(GT,ST)^{***}$} 	& \small{$(TT)^{***}$}	& \small{$(TT)^{***}$} 	&				&	\small{$(SG)^{***}$}		&	\small{$(GG)^{***}$}\\
		\hline
		Inkr. (s)$_2$				& 0,523 & 0,509	& 0,555 &	1,336	&	1,435	&	1,350\\
		\hline
		Inkr. (s)$_3$				& 0,552 & 0,583	& 0,561 &	1,279	&	1,266	&	1,361\\
		\hline
		Inkr. (d) 				& $\textbf{2,795}$ & $\textbf{3,365}$	& $\textbf{3,242}$ &	4,865	&	4,593	&	4,720\\		
									& \small{$(GT,ST)^{**}$} & \small{$(TT){**}$}	& \small{$(TT){**}$}  &	&	&	\\	
		\hline				
		Popup 				& 0,778 & 0,795	& 0,777 &	$\textbf{1,335}$		&	$\textbf{1,067}$ &\\	
									& 			& 			&  			&	\small{$(GG)^{*}$}	&	\small{$(TG)^{*}$} &		\\	
		\hline
		1. Bu.  		& $\textbf{1,765}$ 						& $\textbf{1,990}$		& $\textbf{1,983}$ 	&				& 			&   \\
									& \small{$(GT)^{*},(ST)^{**}$}	& \small{$(TT)^{*}$}		& \small{$(TT)^{**}$}&			& 		& 	\\
		\hline	
		2. Bu.  		& 0,613 & 0,647	& 0,664 &			& 			& 	 \\
		\hline
		3. Bu.  		& 0,631 & 0,633	& 0,662 &				& 			& \\
		\hline		
		Bu. >3 			& \multicolumn{3}{|c|}{0,501}&				& 			& 	 \\
		\hline		
		OK  					& 0,838 & 0,892 &	0,856 & 			& 			&  		\\
		\hline
  \end{tabular}
	\caption[Durchschnittszeiten der Aktionen nach dem Moduswechsel]{Durchschnittszeiten von Touch und Geste in Sekunden der Aktionen nach dem Moduswechsel. Signifikanz wurde gemessen innerhalb einer Modalität nach dem Wechsel (zum Beispiel TT, GT und ST). Fettgedruckte Zeiten sind signifikant. Unter der Zahl steht zu welcher Kombination diese Zeit signifikant ist. Dabei gilt zusätzlich: * Signifikanz $\leq 0,05$, ** Signifikanz $\leq 0,01$ und *** Signifikanz $\leq 0,001$}
	\label{tab:OperatorzeitenNachWechsel_TouchGeste}
\end{table}

\begin{table}[ht]
  \centering
	\begin{tabular}{|l|l|l|l|}
		\hline
		& 					\multicolumn{3}{|c|}{Sprache (S)}\\
		\hline
		Aktion 					& TS 	& GS 	& SS\\
		\hline
		Maria M.	
							&	$\textbf{2,961}$						& $\textbf{3,112}$							& $\textbf{2,802}$\\
							&	\small{$(GS)^{*},(SS)^{**}$}	& \small{$(TS)^{*},(SS)^{***}$}	& \small{$(TS)^{**},(GS)^{***}$}\\
		\hline
		80 \% 				&	$\textbf{3,126}$		& $\textbf{3,298}$ 							& $\textbf{2,914}$\\		
									&	\small{$(SS)^{**}$}	& \small{$(SS)^{***}$} & \small{$(TS)^{**},(GS)^{***}$}\\	
		\hline				
		Popup 				&	1,941	& $\textbf{1,906}$ 		& $\textbf{2,100}$\\	
									& 			& \small{$(SS)^{**}$} 	& \small{$(GS)^{**}$}\\	
		\hline	
		Wort S  			& $\textbf{2,627}$	& $\textbf{2,785}$		& $\textbf{2,346}$ \\
									& \small{$(SS)^{*}$}& \small{$(SS)^{***}$}	& \small{$(TS)^{*},(GS)^{***}$} \\
		\hline
		Wort M 				& 2,829 & $\textbf{2,956}$ 	& $\textbf{2,706}$ \\
									& 			& \small{$(SS)^{*}$} & \small{$(GS)^{*}$} \\
		\hline
		Wort L 				&	3,055	& 2,930	& 2,970\\
		\hline		
		OK  					&	1,933	& 1,964	& 1,988\\
		\hline
  \end{tabular}
	\caption[Erste Vereinfachung der Durchschnittszeiten der Aktionen nach dem Moduswechsel]{Durchschnittszeiten von Sprachbefehlen in Sekunden der Aktionen nach dem Moduswechsel. Signifikanz wurde gemessen innerhalb einer Modalität nach dem Wechsel (zum Beispiel TT, GT und ST). Fettgedruckte Zeiten sind signifikant. Unter der Zahl steht zu welcher Kombination diese Zeit signifikant ist. Dabei gilt zusätzlich: * Signifikanz $\leq 0,05$, ** Signifikanz $\leq 0,01$ und *** Signifikanz $\leq 0,001$}
	\label{tab:OperatorzeitenNachWechsel_Sprache}
\end{table}

Um das Modell etwas zu vereinfachen fassen wir einige der Zeiten zusammen. Alle Aktionen, die nicht unmittelbar nach einem Moduswechsel stattfinden. Diese Aktionen unmittelbar nach einem Moduswechsel sind L$_1$ (der erste Swipe aus den Kontakten), Inkr. (s)$_1$ (der erste Swipe, um die Temperatur zu inkrementieren), Inkr. (d) (Einstellung des Sliders) und 1. Bu. (der erste Touch des ersten Buchstaben). All diese Aktionen weisen auch signifikante Unterschiede untereinander auf, siehe \fref{tab:OperatorzeitenNachWechsel_TouchGeste}, \fref{tab:OperatorzeitenNachWechsel_Sprache}. 

Als ersten fassen wir die Zeiten der direkten Auswahl (DA) zusammen, die vor einem Moduswechsel stattfinden und somit keinen Einfluss eines Wechsel haben können. 
Obwohl die Direktauswahl aus sichtbaren Elementen auf dem ersten Screen zwischen GG und GS und beim zweiten Screen zwischen TG und TS einen signifikanten Unterschied haben (siehe \fref{tab:OperatorzeitenVorWechsel1}), werden wir diese trotzdem für jede Modalität zusammenfassen. Jetzt haben wir noch sechs verschiedene Durchschnittszeiten (je Touch, Geste und Sprache für DA$_1$ und DA$_2$)

Die Zeiten von DA$_1$ und DA$_2$ unterscheiden sich, jedoch ist es schwer zu begründen an welchen Variablen dieser Unterschied liegt. 
\begin{figure}
	\centering
		\includegraphics[width=1\textwidth]{img/Screen1vsScreen2.JPG}
	\caption{Unterschiedliche Varianten einer Direktauswahl}
	\label{fig:Screen1vsScreen2}
\end{figure}
Die Größe der Buttons ist zwar gleich, jedoch ist die Anzahl der Buttons unterschiedlich. Es gibt auf dem zweiten Screen nur 3 Buttons, statt der 4 Buttons im ersten Screen. 
Außerdem sind im Hauptscreen Icons und Texte und auf dem zweiten Screen nur Text abgebildet (siehe \fref{fig:Screen1vsScreen2}). Wir hätten zur Vereinfachung gerne eine einheitliche Durchschnittszeit der drei Modalitäten für diese Aktion (DA). Also die durchschnittliche Zeit, die für eine Auswahl von 3-4 Buttons der Größe 3,5cm x 4,5cm mit Text oder Icons benötigt wird. 
Deshalb haben wir uns entschlossen die Zeiten zusammenzufassen (siehe \fref{tab:OperatorzeitenZusammengefasst1}).

Als nächstes fassen wir Aktionen zusammen, bei denen der Moduswechsel bereits stattgefunden hat. 
Der erste Swipe beispielsweise ist unmittelbar nach einem potenziellen Moduswechsel. 
Ein Moduswechsel beinhaltet einen Homing Operator wie aus dem ursprüngliche KLM. 
Bei Sprache zum Beispiel sind die Hände meist am Lenkrad. 
Wechselt die Modalität von Sprache zu Touch muss die Hand vom Lenkrad genommen werden und sich zum Touchbereich bewegen. 
Nach \citet{Green_2002} würde das dem Operator $R_f$ (Reach Far) entsprechen. 
Eine Aktion unmittelbar nach einem Moduswechsel dauert also länger, was sich aus unseren ermittelten Zeiten auch bestätigen lässt. 

Deshalb fassen wir für den zweiten und dritten Swipe der Liste (L$_2$), (L$_3$) die Modalität vor dem Moduswechsel zusammen. Subtrahieren wir diese Durchschnittszeit von (L$_1$) bekommen wir sozusagen die Vorbereitungszeit, die unsere Nutzer gebraucht haben, um zum Beispiel Ihre Hand zu bewegen und sich mental auf die Aufgabe vorzubereiten. Es entsteht also die einheitliche Aktion (L) für alle seitenweise Swipes und zusätzlich eine Vorbereitungszeit, die zum ersten Swipe addiert werden muss. Die Vorbereitungszeit unterscheiden wir für jede Modalität und somit bekommen wir die Aktion V(L), siehe \fref{tab:OperatorzeitenNachWechsel3_TouchGeste}.
 
Das gleiche Vorgehen wenden wir für die Aktion Inkr. (s) an. Wir wollen eine einheitliche Aktion Inkr. (s) und zusätzlich eine Vorbereitungszeit V (Inkr. (s)), die dafür benötigt wird. 
 
Bei der Eingabe von Buchstaben per Touch unterscheiden wir die Zeiten zusätzlich in 2 Gruppen. Wie wir bereits aus der Abbildung \ref{fig:Kategorien} abgeleitet haben gibt es einerseits auch hier eine deutlich längere Zeit für den ersten Buchstaben. 
Zusätzlich nimmt die Zeit der Toucheingabe ab dem vierten Buchstaben nochmal deutlich ab. 
Wir modellieren also einmal eine Zeit für die ersten 3 Buchstaben und addieren für die Vorbereitung eine feste Zeit V(1. Bu) hinzu, wie schon bei den Aktionen L und Inkr. (s). 
Für alle weiteren Buchstaben gibt es eine neue geringere Durchschnittszeit, die verwendet werden soll, siehe \fref{tab:OperatorzeitenNachWechsel3_TouchGeste}.  

\begin{table}[ht]
  \centering
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|}
		\hline
		& \multicolumn{3}{|c|}{Touch} & \multicolumn{3}{|c|}{Geste}&\multicolumn{3}{|c|}{Sprache}\\
		\hline
		Aktion 					& TT 		& TG 		& TS 		& GT 		& GG 		& GS 		& ST 		& SG 		& SS\\
		\hline
		DA 	& \multicolumn{3}{|c|}{1,710} &	\multicolumn{3}{|c|}{2,436} 	&	\multicolumn{3}{|c|}{2,795} \\
		\hline			
  \end{tabular}
	\caption{Zusammengefasste Zeiten der Operatoren vor dem Moduswechsel}
\label{tab:OperatorzeitenZusammengefasst1}
\end{table}
\begin{table}[ht]
  \centering
	\begin{tabular}{|l|l|l|l|l|l|l|}
		\hline
		& \multicolumn{3}{|c|}{Touch (T)} & \multicolumn{3}{|c|}{Geste (G)}\\
		\hline
		Aktion 					& TT 	& GT 	& ST 	& TG 	& GG 	& SG \\
		\hline
		V(L)	& {0,705} 	& {1,116}		& {1,080} 	&	{0,530}		&	{0,425}		&	{0,818}\\
		\hline
		L					& \multicolumn{3}{|c|}{0,813} &	\multicolumn{3}{|c|}{1,372}\\
		\hline
		DA(L)			& \multicolumn{3}{|c|}{1,047} &	\multicolumn{3}{|c|}{2,258}\\
		\hline
		V(Inkr. (s))
										& {0,906} 	& {1,242}		& {1,179} 	&	{0,334}		&	{0,198}		&	{0,407}\\
										& \small{+ 0,547} 	& \small{+ 0,547}	& \tiny{+ 0,547} 	&	\small{+ 1,338}	&	\tiny{+ 1,338}	&	\small{+ 1,338}\\
		\hline
		Inkr. (s)				& \multicolumn{3}{|c|}{0,547} &	\multicolumn{3}{|c|}{1,338}\\
		\hline
		Inkr. (d)				& $\textbf{2,795}$ & $\textbf{3,365}$	& $\textbf{3,242}$ &	4,865	&	4,593	&	4,720	\\		
									& \small{$(GT,ST)^{**}$} & \small{$(TT){**}$}	& \small{$(TT){**}$}  &	&	&		 \\	
		\hline		
		Best. 				& \multicolumn{3}{|c|}{0,829} &	\multicolumn{3}{|c|}{1,200}\\			
		\hline
		V(1. Bu.)
										& {1,123} 	& {1,348}		& {1,341} 	&				& 			&  	\\
										& \small{+ 0,642} & \small{+ 0,642}	& \small{+ 0,642} &				& 			&  		\\
		\hline	
		1-3. Bu.		& \multicolumn{3}{|c|}{0,642} &				& 			&  	 \\
		\hline		
		Bu. >3 					& \multicolumn{3}{|c|}{0,501} &				& 		&  		\\
		\hline	
  \end{tabular}
	\caption[Zweite Vereinfachung Durchschnittszeiten von Touch und Geste nach dem Moduswechsel]{Durchschnittszeiten von Touch und Geste in Sekunden der Aktionen nach dem Moduswechsel. Signifikanz wurde gemessen innerhalb einer Modalität nach dem Wechsel (zum Beispiel TT, GT und ST). Fettgedruckte Zeiten sind signifikant. Unter der Zahl steht zu welcher Kombination diese Zeit signifikant ist. Dabei gilt zusätzlich: * Signifikanz $\leq 0,05$, ** Signifikanz $\leq 0,01$ und *** Signifikanz $\leq 0,001$}
	\label{tab:OperatorzeitenNachWechsel3_TouchGeste}
\end{table}
\begin{table}[ht]
  \centering
	\begin{tabular}{|l|l|l|l|}
		\hline
		& \multicolumn{3}{|c|}{Sprache (S)}\\
		\hline
		Aktion 					&TS 	& GS 	& SS\\
		\hline
		2 Wörter		&	$\textbf{3,043}$						& $\textbf{3,205}$							& $\textbf{2,858}$\\
								&	\small{$(GS)^{*},(SS)^{**}$}	& \small{$(TS)^{*},(SS)^{***}$}	& \small{$(TS)^{**},(GS)^{***}$}\\
		\hline	
		B						&\multicolumn{3}{|c|}{1,972}\\			
		\hline
		Wort   		& $\textbf{2,627}$	& $\textbf{2,785}$		& $\textbf{2,346}$ \\
		einsilbig						& \small{$(SS)^{*}$}& \small{$(SS)^{***}$}	& \small{$(TS)^{*},(GS)^{***}$} \\
		\hline
		Wort  			& 2,917 & $\textbf{2,944}$ 	& $\textbf{2,839}$ \\
		mehrsilbig						& 			& \small{$(SS)^{*}$} & \small{$(GS)^{*}$} \\
		\hline	
  \end{tabular}
	\caption[Zweite Vereinfachung Durchschnittszeiten von Sprache nach dem Moduswechsel]{Durchschnittszeiten von Sprachbefehlen in Sekunden der Aktionen nach dem Moduswechsel. Signifikanz wurde gemessen innerhalb einer Modalität nach dem Wechsel (zum Beispiel TT, GT und ST). Fettgedruckte Zeiten sind signifikant. Unter der Zahl steht zu welcher Kombination diese Zeit signifikant ist. Dabei gilt zusätzlich: * Signifikanz $\leq 0,05$, ** Signifikanz $\leq 0,01$ und *** Signifikanz $\leq 0,001$}
	\label{tab:OperatorzeitenNachWechsel3_Sprache}
\end{table}

Im nächsten Schritt werden wir das Modell noch etwas weiter vereinfachen, um es möglichst universell anwenden zu können. 

Bei der Aktion Swipe Liste muss für die Modalität Sprache lediglich "`Maria Müller"' gesagt werden, um in der Liste zur richtigen Position zu scrollen. Bei der Aktion Slider muss "`80 Prozent"' gesagt werden um den Wert auf 80 Prozent zu ändern. Da beides die Dauer darstellt, die für 2 Wörter benötigt wird, wollen wir diese Zeiten trotz signifikanter Unterschiede zusammenfassen (siehe \fref{tab:OperatorzeitenNachWechsel3_Sprache}), um das Modell einfach zu halten. 

Ähnlich dazu, wollen wir die Zeiten für Touch und Sprache des Bestätigungspopups und des Ok Buttons verbinden und dies als einheitliche Aktion Bestätigung (B) zusammen fassen. Bei Touch und Sprache gibt keine signifikanten Unterschiede zwischen dem Popup und dem Ok Button.

Als letztes fassen wir die Wortlängen M und L zusammen. Diese sind beide signifikant unterschiedlich zur Wortlänge S, aber gegenseitig weisen sie keine signifikanten Unterschiede auf. Die Unterscheidung der Modalitäten wird allerdings erhalten, da unmittelbar davor der Moduswechsel statt gefunden hat. Bei diesen Aktionen wird jetzt lediglich unterschieden, ob sie einsilbig oder mehrsilbig sind. Diese Aktionen kürzen wir ab mit Wort(e) für ein einsilbiges Wort und Wort(m) für ein mehrsilbiges Wort.

\section[Multimodales Modell]{Multimodales Modell mit Wechselkosten}
In den letzten Schritten haben wir die gesammelten Durchschnittszeiten gruppiert und zusammengefasst. Um das Ganze übersichtlich zu einem Modell zu bekommen betrachten wir jetzt die Aktionen vorerst unimodal (TT, GG und SS) und addieren je nach Moduswechsel die dementsprechenden Wechselkosten hinzu. 

Die unimodalen Interaktionszeiten waren immer schneller als die multimodalen Interaktionszeiten. Wir verwenden diese als unsere Ausgangszeiten, indem wir sie von den Multimodalen Varianten subtrahieren. Dadurch entstehen dann die sogenannten zusätzlichen Wechselkosten. Zum Beispiel die V(L) dauert für TT 0,705 Sekunden und für die multimodale Variante GT 1,116 Sekunden. Ziehen wir die unimodale Zeit von der multimodalen ab erhalten wir die Wechselkosten von 0,411 Sekunden, die bei einem Wechsel von Geste zu Touch (W$_{GT}$) anfallen. 

Insgesamt haben wir jetzt die DA für Touch, Geste und Sprache vor einem Moduswechsel und 10 Aktionen nach einem möglichen Moduswechsel für Touch und Geste und 4 Aktionen nach einem möglichen Moduswechsel für Sprache. Dazu kommen die jeweiligen Wechselkosten unmittelbar nach einem Wechsel.

In \fref{tab:DA} sind die zusammengefassten Zeiten der Aktion DA, die vor dem Moduswechsel stattfinden und in \fref{tab:AktionenUnimodal} sind alle Aktionen mit ihren Interaktionszeiten aufgelistet. Wird eine dieser Aktionen mit einer anderen Modalität ausgeführt als die DA müssen die Wechselkosten addiert werden.
Die dazugehörigen Wechselkosten für multimodale Interaktionen können aus \fref{tab:Wechselkosten} entnommen werden.
\begin{table}[ht]
  \centering
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|}
		\hline
		& \multicolumn{3}{|c|}{Touch} & \multicolumn{3}{|c|}{Geste}&\multicolumn{3}{|c|}{Sprache}\\
		\hline
		Aktion 					& TT 		& TG 		& TS 		& GT 		& GG 		& GS 		& ST 		& SG 		& SS\\
		\hline
		DA 	& \multicolumn{3}{|c|}{1,710} &	\multicolumn{3}{|c|}{2,436} 	&	\multicolumn{3}{|c|}{2,795} \\
		\hline			
  \end{tabular}
	\caption{Zusammengefasste Zeiten der Operatoren vor dem Moduswechsel}
\label{tab:DA}
\end{table}
\begin{table}[ht]
  \centering
			\begin{tabular}{|l|l|l|l|}
					\hline
				& \multicolumn{3}{|c|}{Unimodal}\\
				\hline
				Aktion 					& Touch & Geste & Sprache \\
				\hline
				V (L$_1$) 		& {0,705} 	&	{0,425}	&	\\
				\hline
				je (L)				& {0,813} &	{1,372} &\\
				\hline
				DA(L)						& {1,047} &	{2,258} & \\
				\hline
				V(Inkr. (s))		& {0,906} &	{0,198} &\\
				\hline
				Inkr. (s)			& {0,547} &	{1,338} &\\
				\hline
				Inkr. (d)					& {2,795} &	4,593 & \\		
				\hline		
				Bestätigung 		& {0,829} &{1,200} & {1,972}\\			
				\hline
				V(1. Bu.)					& {1,123} 	& 	&\\
				\hline	
				1-3. Bu.					& {0,642} & 	& \\
				\hline		
				Bu. >3 					& {0,501}		&  	& \\
				\hline	
				Wort(e)					& & & {2,346} \\
				\hline		
				Wort(m) 				& & & {2,839}\\
				\hline
				2 Wörter 				& & & {2,858}\\
				\hline
			\end{tabular}
	\caption{unimodale Interaktionszeiten.}
	\label{tab:AktionenUnimodal}
\end{table}
\begin{table}[ht]
  \centering
		\begin{tabular}{|l|l|l|l|l|l|l|}
				\hline
				& \multicolumn{6}{|c|}{Multimodalmodale Wechselkosten}\\
				\hline
				Aktion 					& Geste zu		& Sprache zu 	& Touch zu		& Sprache zu		& Touch zu		& Geste zu\\
												& Touch 			& Touch 			& Geste 			& Geste					& Sprache 		& Sprache \\
				\hline
				L$_1$ 					& ${+0,411}$ 	&	${+0,375}$	& ${+0,105}$ 	&	${+0,393}$		& \multicolumn{2}{|c|}{}	\\
				\hline
				Inkr. (s)$_1$		& ${+0,336}$ 	&	${+0,273}$ 	& ${+0,136}$ 	&	${+0,209}$		& \multicolumn{2}{|c|}{}	\\
				\hline
				Inkr. (d) 					& ${+0,570}$ 	&	${+0,447}$ 	& ${+0,272}$ 	&	${+0,127}$		& \multicolumn{2}{|c|}{}	\\		
				\hline
				1. Buchstabe		& ${+0,225}$ 	& ${+0,218}$ 	&	\multicolumn{2}{|c|}{}			& \multicolumn{2}{|c|}{}	\\
				\hline
				Wort(e) 	& \multicolumn{2}{|c|}{}	& \multicolumn{2}{|c|}{}				& ${+0,281}$ 		& ${+0,439}$\\			
				\hline
				Wort(m)	& \multicolumn{2}{|c|}{}	& \multicolumn{2}{|c|}{}				& ${+0,079}$ 		& ${+0,105}$\\	
				\hline					
				2 Wörter 				& \multicolumn{2}{|c|}{}	& \multicolumn{2}{|c|}{}				& ${+0,185}$ 		& ${+0,347}$\\	
				\hline	
			\end{tabular}
	\caption[Wechselkosten eines Moduswechsels]{Zusatzkosten (Wechselkosten) in Sekunden bei einem Moduswechsel. Diese Wechselkosten betreffen nur Aktionen direkt nach dem Moduswechsel. Wechselkosten müssen bei einem Moduswechsel dementsprechend aufaddiert werden.}
	\label{tab:Wechselkosten}
\end{table}

Aus unserem Prototyp ergeben sich noch 3 Antwortzeiten. Einmal der Wechsel zwischen den Screens mit einer Zeit von 0,016 Sekunden. Um dem Nutzer beim Anwendungsbeispiel Telefon Feedback zu geben, wurde bei der Modalität Sprache nach dem Sprachbefehl "`Maria Müller"' eine Animation eingebaut, die die Liste scrollen lässt, bevor der Kontakt markiert wird. Diese Animation dauert 1,5 Sekunden. Bei der Spracheingabe zur Direktauswahl aus sichtbaren Elementen wurde 0,5 Sekunden gewartet, um die Markierungsfarbe zu sehen. 
Solche konstanten Zeiten sind nicht übertragbar, sondern müssen für jedes neue Interface das getestet wird berechnet und in die Vorhersage miteinbezogen werden. Für die Evaluation benötigen wir diese Zeiten.

\section[Qualitative Auswertung]{Qualitative Auswertung der Studie}
Diese Art der Auswertung kann nicht in Zahlen ausgedrückt werden, sondern beinhaltet Kommentare der Probanden, sowie Beobachtungen des Studienleiters während der Studie.

Die Studiendauer von 1,5 Stunden war sehr lange. Es konnte beobachtet werden, dass die Konzentration mit der Zeit oft nach ließ. Hinzu kam, dass es Anfang Dezember teils sehr kalt in der Parkgarage war. Je nach Vorlieben konnte die Sitzheizung eingeschaltet werden, jedoch wurden bei einigen mit der Zeit die Hände kalt. 

Die Verwendung von Gesten als Eingabemodalität erwies sich als sehr unterschiedlich bei den Probanden. Obwohl einige Schwierigkeiten bei der Gestenerkennung auftauchten, machte es den meisten sehr viel Spaß damit zu interagieren. Es fiel auf, dass Probanden, bei dem die Gesteninteraktion sehr gut funktionierte natürlich auch der Eindruck viel positiver war. Ein Grund weshalb die Gestenerkennung unterschiedlich gut funktioniert hat, war der festgelegt Interaktionsbereich zwischen Gangschaltung und Dashboard, siehe \fref{fig:GestenbereichSkizze}. 
\begin{figure}
	\centering
		\includegraphics[width=1\textwidth]{img/GestenbereichSkizze2.jpg}
	\caption{Skizze des Interaktionsbereichs zur Gestenerkennung}
	\label{fig:GestenbereichSkizze}
\end{figure}

Je nach Einstellung des Sitzes und vor allem je nach Armlänge der Probanden befand sich die Hand mehr oder weniger bequem im Interaktionsbereich. Am besten erschien eine Variante, bei dem der Proband seinen Arm auf der Armlehne ablegen konnte. Ist der komplette Arm in der Luft, wird er schnell schwer und die Gesten sind schwieriger auszuführen. Befindet sich die Hand zu weit hinten kommen die Infrarotstrahlen der Leap nicht durch die Gangschaltung und die Gestenerkennung funktioniert nicht so gut oder gar nicht. Es ist wichtig, dass dieser Bereich individuell einstellbar sein sollte, um die Gestenerkennung so bequem und robust wie möglich zu gestalten.

Bei der Toucheingabe ist aufgefallen, dass sie zwar keinerlei Schwierigkeiten bei der Interaktion machte, allerdings befand sich der Touchbereich etwas zu weit hinten. Einige der Probanden mussten sich etwas nach vorne lehnen, um ihn optimal zu erreichen. Das stellt für die Bedienung im stehenden Auto kein Problem dar, jedoch während Fahrt sollte das vermieden werden, um möglichst wenig abzulenken. Das Inputfeld im Screen der Texteingabe befand sich unter der Tastatur. Bei der Toucheingabe wurde es durch die Hand verdeckt. Es sollte sich besser über der Tastatur befinden. 

Aus Kommentaren einiger Probanden kam heraus, dass sie einerseits die Sprachbedienung für während der Fahrt am geeignetsten halten. Andererseits wurde angemerkt, dass sie die Sprachbedienung eher allein im Auto nutzen würden als mit Mitfahrern. Das deutet wiederum auf die Vorteile von multimodale Interaktion hin, bei der eine beliebige Variante je nach Situation gewählt werden kann.

Die multimodale Ausführung von Interaktionen kam insgesamt sehr gut an. Immer wieder wurde jedoch angemerkt, dass haptische Bedienelemente für die Inkrementation besser geeignet wären. 

\section[Diskussion]{Diskussion zur Studie und Erstellung des Modells}
Bei der Entwicklung des Prototypen und der Erhebung der Interaktionszeiten aus der Studie gab es einige Einschränkungen und Entscheidungen, die im Zusammenhang der Studienergebnisse im folgenden interpretiert werden sollen.

Als erste Einschränkung haben wir die Interaktion mit klassischen haptischen Bedienelementen aus unserer Studie ausgeschlossen. Dies lag dem großen Mehraufwand zugrunde, der dabei entstanden wäre. Um haptische Bedienelemente befriedigend zu modelliere, müssten, um nur ein Beispiel zu nennen verschiedene Drehwinkel eines Drehrades gemessen werden \citep{schneegass_2009}. Allein durch unsere drei Modalitäten mit Touch, Sprache und Geste entstanden mit unseren Aktionen ein Studienumfang von 1,5 Stunden, in der alle Kombinationen der drei Modalitäten getestet wurden. Wir haben uns entschieden uns in dieser Arbeit auf neuere Modalitäten (Touch, Sprache und Geste) zu fokussieren. 

Die Bedienung im Auto durch haptische Knöpfe, Schalter und Regler ist und bleibt ein wichtiger Bestandteil, um Funktionen im Auto zu betätigen. Ein großer Vorteil ist, dass die Eingabe oft fast blind getätigt werden kann, ohne die Aufmerksamkeit zu viel von der Straße zu lenken. Jedoch wurde bereits in vorherigen Studien die Verwendung von haptischen Bedienelementen im Auto untersucht \citep{Pettitt_2007}, \citep{schneegass_2009} und \citep{SchneegaB_2011}. 

In unserer Studie zur Erhebung von multimodalen Interaktionszeiten verwenden wir keine Fahraufgabe. Stattdessen messen wir die Total Task Time, die in einem stehenden Auto benötigt wird um eine Aufgabe zu lösen \citep{green1999sae}. Um den Grad der visuellen Ablenkung, solcher multimodalen Interaktionen messen zu können, sollte unser Modell zusätzlich noch dahingehend erweitert werden, die visuelle Ablenkung miteinzuberechnen (siehe \citep{Pettitt_2007}.

Unsere Aktionen des multimodalen Modells sind nicht so feingranular wie die Operatoren aus dem Keystroke-Level-Modell. Statt separate Zeiten für die mentale Vorbereitung, der Bewegung vom Lenkrad zum Interaktionsbereich und der Bewegung innerhalb eines Interaktionsbereichs zu modellieren, haben wir diese als durchschnittliche Vorbereitungszeit für 3 verschiedenen Aktionen je nach Modalität zusammengefasst. Bei der Modellierung des Keystroke-Level-Modell wird genau vorgegeben, wann der Experte welche Bewegung macht und wann er sich mental vorbereitet. 

Diese Herangehensweise war uns für unser Modell zu genau und hätte per Videoanalyse ausgewertet werden müssen. Um die Akkudauer der Go Pro zu verlängern, haben wir die Auflösung verringert. Die Bildqualität reicht aus, um die Varianten nachzuvollziehen, für eine Videoanalyse zur Bestimmung von Operatoren ist sie eher ungeeignet. Es wurden über 22 Stunden Videomaterial aufgenommen.

Für unser Modell wollten wir Zeiten, die ein geübter Nutzer im Durchschnitt benötigt, um eine bestimmte Aktion in einem bestimmten Modus auszuführen. Das Modell soll eine grobe Abschätzung der Interaktionszeiten in Abhängigkeit der Modalität darstellen. Das ist auch der Grund warum wir unser Modell bis zum jetzigen Stand aggregiert haben. Doch selbst diese grobe Abschätzung sollte Vergleiche zwischen verschiedenen Moduskombination der Aktionen zulassen. Es ist jedoch zu erwarten, dass die Vorhersage der Interaktionszeiten eventuell nicht ganz so genau sind wie die eines Keystroke-Level Modells.

Um für alle Kombinationen ausreichend Zeiten erheben zu können musste jeder Nutzer im Within Subject Design alle 33 Kombinationen durchführen. Da wir in unserem Modell, wie bei dem Keystroke-Level-Modell \citep{Card_1980}, von Experten ausgehen wollen, mussten die Probanden der Studie vorher die Interaktion üben. 

\citet{Jude:2014} zeigte in seinem Paper zu multimodaler Interaktion von Geste und Sprache, dass eine sehr schnelle Interaktionssteigerung mit relativ geringem Training zu beobachten ist. 
Außerdem entschlossen wir uns von jedem Probanden zwei Messdurchgänge zu erheben, um somit die Durchschnittszeit beider Messdurchgänge verwenden zu können. Diese Vorkehrungen bedeuteten allerdings, dass die Studiendauer bis zu 1,5 Stunden dauerte (je nachdem wie viel geübt werden musste). Die Studiendauer von 1,5 Stunden ist sehr lange und es konnte beobachtet werden, dass die Konzentration bei einigen Probanden mit der Zeit abnahm. Durch unsere Permutation aller Modalitäten und Anwendungsbeispielen, sollten diese eventuellen negativen Effekte auf alle Varianten gleichermaßen verteilt sein.

Die Vorerfahrung von Sprache ergab im Durchschnitt 2,32, bei Touch 3,95 und bei Geste 1,86. Die große Erfahrung mit der Touchbedienung lässt sich auf die weitverbreitete Smartphonenutzung zurückführen. Mit der Gestensteuerung haben die Probanden wie erwartet am wenigsten Erfahrung. Acht der 22 Probanden hatten keine Erfahrungen mit der Gestensteuerung und keiner davon nutzt sie regelmäßig. Diese Erfahrungswerte liegen der wenig verbreiteten Anwendungen mit Gesteninteraktionen zu Grunde.

Bei unserem Modell konnten wir für die Modalität Sprache nur zwischen einsilbigen Wörtern und mehrsilbigen Wörtern, sowie einer Durchschnittszeit von zwei Wörtern unterscheiden. In den meisten gängigen IVIS mit Sprachbedienung können auch ganze Sätze gesprochen werden wie zum Beispiel "`navigiere in die Kirchengasse Nummer 17"'. Um die Dauer eines Satzes zu modellieren müsste unser Modell noch dahingehend erweitert werden. 

Die Aktion Direktauswahl aus sichtbaren Elementen sollte noch erweitert werden, dass sie auch nach einem Wechsel modelliert stattfinden kann. In unseren Anwendungsbeispielen kam diese Variante nicht vor und konnte somit nicht modelliert werden.

Der Gesteninteraktionsbereich war nicht für alle Probanden optimal, je nach Armlänge konnten die Gesten der Probanden besser und schlechter ausgeführt werden. Probanden, bei denen sich der Interaktionsbereich zu weit weg befand, mussten sich mehr darauf konzentrieren die Geste richtig auszuführen, was die Interaktion verlangsamte und die potenzielle Ablenkung vergrößert. In der Studie von \citet{Riener:2013:SIG} wurde der Bereich für Gesten untersucht. 
Sie stellten fest, dass die häufigste Gesteninteraktion sich in dem Dreiecks-Bereich von Lenkrad, Rückspiegel und Gangschaltung befindet. 
Unsere Gestenerkennung befand sich somit innerhalb dieses Bereichs.

Auch der Touchdisplay war für einige Probanden zu weite vorne positioniert. Diese Aspekte sollten bei der Entwicklung von multimodalen Informationssystemen im Auto mehr berücksichtigt werden. Zur Optimierung der Interaktion mit großen Touchdisplays haben \citet{Rumelin:2013} Touchvarianten verglichen und zum Beispiel ein haptisches Element als Orientierungshilfe in den Screen eingebaut, mit dem die Interaktion eines Kuchenmenüs von diesem Punkt aus fast blind getätigt werden kann. Um visuelle Überlagerungen von Karten zu verbessern haben \citet{lee2013saliency} die Suche von Elementen durch die präattentive Wahrnehmung durch das Hervorheben von Elementen verbessert und konnten somit Ablenkung reduzieren. Es gibt also nicht nur für die Kombination von Modalitäten, sondern auch für jede einzelne Modalität noch Verbesserungspotenzial. 

Grundsätzlich lässt sich sagen, dass die Sprachbedienung am beliebtesten bei den Probanden war. Jedoch wurde oft angemerkt, dass Sie diese Modalität nicht mit Mitfahrern verwenden würden. Das ist ein gutes Beispiel dafür, warum es sinnvoll ist bei einem IVIS mehrere Modalitäten anzubieten. Nach der reinen Sprachbedienung war die zweitbeliebteste Kombination Touch und Sprache, dicht gefolgt von Geste und Sprache. Das zeigt, dass multimodale Interaktionen durchaus bei den Probanden gewünscht sind. 