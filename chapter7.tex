\chapter{Zusammenfassung und Ausblick}\label{cha:Zusamenfassung}
Motiviert durch die Vorteile verschiedener Modalitäten und die damit verbundene Möglichkeit den Nutzer zu entlasten und ihn somit weniger von der Fahraufgabe abzulenken. Der Fahrer kann selbst entscheiden in welchen Situationen welcher Modus für den jeweiligen Schritt am geeignetsten und ungefährlichsten ist, was auch laut \citet{Muller_2011} einen wesentlichen Vorteil in Autos darstellt.

Deshalb war unsere Motivation solche multimodalen Interaktionen in IVIS besser verstehen zu können und diese optimal umsetzen zu können. Mit der Entwicklung unsres Modells zur Vorhersage von multimodalen Interaktionszeiten ist es uns gelungen Designer die Möglichkeit zu geben bereits in einem frühem Stadium der Entwicklungsphase multimodale Interaktionen einzuschätzen und zu vergleichen. Damit können Designer in geeigneter Weise die besten potenziellen Varianten unterstützen, um dem Fahrer auch die besten Möglichkeiten in verständlicher Weise anzuzeigen. Damit soll natürlich auch die visuelle und mentale Beanspruchung für den Fahrer so gering wie möglich gehalten werden. 

Ob eine Variante besonders gut oder schlecht ist hängt natürlich von der Situation ab, Deshalb wäre ein seriell redundantes multimodalen IVIS am besten, um in jedem Schritt den Fahrer selbst die beste Modalität wählen zu lassen. Die Eingabe eines Zieles per Touch ist zum Beispiel im stehenden Auto eine gute Variante, die jedoch während der Fahrt den Fahrer durch die längere Interaktion zu sehr ablenken könnte. In diesem Fall stellt die Texteingabe per Sprache eine sehr geeignete Alternative dar.

Unser Modell zur Vorhersage von multimodalen Interaktionen im IVIS sollte in Zukunft noch dahingehend weiterentwickelt werden auch haptische Bedienelemente miteinzubeziehen. Zudem kann das Modell auf weitere Gesten erweitert werden und auch die weitere Untersuchungen von gesprochenen Sätzen könnte hilfreich sein.

Im Zuge dieser Masterarbeit wurde im Workshop Connected Minds die Bedienung im Fahrzeug beobachtet und diskutiert. Es wurde ein Konzept für ein multimodales Modell entworfen und in einem multimodalen Prototypen umgesetzt. Dieser kann mit Touch, Sprache und Geste bedient werden. Zur Erhebung der Interaktionszeiten und der Evaluierung des Modells wurde der Prototyp seriell exklusiv umgesetzt, da dem Nutzer die Modalität vorgegeben war. Unser Modell unterscheidet verschiedene Aktionen in Abhängigkeit der Modalität und enthält entstehende Wechselkosten wenn der Nutzer die Modalität ändert. 